"""
Tool especializada para an√°lise de regulamenta√ß√£o financeira brasileira
"""

from crewai_tools import BaseTool
from typing import Type, Any, List, Dict
from pydantic import BaseModel, Field
from src.document_processor import DocumentProcessor
from src.utils.logger import setup_logger
import re

logger = setup_logger(__name__)

class RegulationAnalyzerInput(BaseModel):
    """Input para an√°lise de regulamenta√ß√£o"""
    regulation_topic: str = Field(..., description="T√≥pico espec√≠fico da regulamenta√ß√£o a ser analisado")
    focus_areas: List[str] = Field(default=[], description="√Åreas espec√≠ficas de foco (opcional)")

class RegulationAnalyzerTool(BaseTool):
    name: str = "regulation_analyzer"
    description: str = """Ferramenta especializada para an√°lise de regulamenta√ß√£o financeira brasileira.
    Extrai e estrutura informa√ß√µes sobre:
    - Obriga√ß√µes e responsabilidades
    - Prazos e deadlines
    - Penalidades e sanctions
    - Requisitos t√©cnicos e operacionais
    - Fluxos obrigat√≥rios
    
    Ideal para:
    - An√°lise de compliance
    - Mapeamento de riscos regulat√≥rios
    - Identifica√ß√£o de gaps de conformidade
    - Planejamento de implementa√ß√£o
    """
    args_schema: Type[BaseModel] = RegulationAnalyzerInput
    
    def _run(self, regulation_topic: str, focus_areas: List[str] = None) -> str:
        try:
            processor = DocumentProcessor()
            
            # Buscar documentos relevantes
            results = processor.search_documents(regulation_topic, 20)
            
            if not results:
                return f"Nenhuma regulamenta√ß√£o encontrada para: {regulation_topic}"
            
            # Analisar e estruturar informa√ß√µes
            analysis = self._analyze_regulation_content(results, focus_areas or [])
            
            return self._format_analysis(regulation_topic, analysis)
            
        except Exception as e:
            logger.error(f"Erro na an√°lise de regulamenta√ß√£o: {str(e)}")
            return f"Erro ao analisar regulamenta√ß√£o: {str(e)}"
    
    def _analyze_regulation_content(self, results: List[Dict], focus_areas: List[str]) -> Dict:
        """Analisar conte√∫do regulat√≥rio e extrair informa√ß√µes estruturadas"""
        
        analysis = {
            'obligations': [],
            'deadlines': [],
            'penalties': [],
            'technical_requirements': [],
            'key_articles': [],
            'focus_analysis': {}
        }
        
        for result in results:
            content = result['content']
            metadata = result['metadata']
            
            # Extrair obriga√ß√µes (verbos imperativos)
            obligations = re.findall(r'(?:deve|dever√°|√© obrigat√≥rio|√© necess√°rio|obriga-se)[\s\w,.:;-]+[.!]', content, re.IGNORECASE)
            analysis['obligations'].extend([{
                'text': ob.strip(),
                'source': metadata['filename']
            } for ob in obligations[:3]])  # Limitar a 3 por documento
            
            # Extrair prazos
            deadlines = re.findall(r'(?:prazo de|at√©|no prazo m√°ximo de|em at√©)\s+\d+\s+(?:dias|meses|anos)[\s\w,.:;-]*[.!]', content, re.IGNORECASE)
            analysis['deadlines'].extend([{
                'text': dl.strip(),
                'source': metadata['filename']
            } for dl in deadlines[:2]])
            
            # Extrair penalidades
            penalties = re.findall(r'(?:multa|penalidade|san√ß√£o|advert√™ncia)[\s\w,.:;-]+[.!]', content, re.IGNORECASE)
            analysis['penalties'].extend([{
                'text': pen.strip(),
                'source': metadata['filename']
            } for pen in penalties[:2]])
            
            # Extrair artigos importantes
            articles = re.findall(r'(?:Art\.|Artigo)\s+\d+[\s\w,.:;-]+[.!]', content)
            analysis['key_articles'].extend([{
                'text': art.strip(),
                'source': metadata['filename']
            } for art in articles[:2]])
            
            # An√°lise focada em √°reas espec√≠ficas
            for area in focus_areas:
                if area.lower() in content.lower():
                    if area not in analysis['focus_analysis']:
                        analysis['focus_analysis'][area] = []
                    
                    # Extrair par√°grafos relevantes
                    sentences = content.split('.')
                    relevant_sentences = [s.strip() + '.' for s in sentences if area.lower() in s.lower()]
                    
                    analysis['focus_analysis'][area].extend([{
                        'text': sent,
                        'source': metadata['filename']
                    } for sent in relevant_sentences[:2]])
        
        return analysis
    
    def _format_analysis(self, topic: str, analysis: Dict) -> str:
        """Formatar an√°lise em texto estruturado"""
        
        sections = [
            f"AN√ÅLISE REGULAT√ìRIA: {topic.upper()}",
            "=" * 50,
            ""
        ]
        
        # Obriga√ß√µes
        if analysis['obligations']:
            sections.extend([
                "üìã OBRIGA√á√ïES E RESPONSABILIDADES:",
                ""
            ])
            for i, obligation in enumerate(analysis['obligations'][:5], 1):
                sections.append(f"{i}. {obligation['text']}")
                sections.append(f"   Fonte: {obligation['source']}")
                sections.append("")
        
        # Prazos
        if analysis['deadlines']:
            sections.extend([
                "‚è∞ PRAZOS E DEADLINES:",
                ""
            ])
            for i, deadline in enumerate(analysis['deadlines'][:3], 1):
                sections.append(f"{i}. {deadline['text']}")
                sections.append(f"   Fonte: {deadline['source']}")
                sections.append("")
        
        # Penalidades
        if analysis['penalties']:
            sections.extend([
                "‚ö†Ô∏è PENALIDADES E SAN√á√ïES:",
                ""
            ])
            for i, penalty in enumerate(analysis['penalties'][:3], 1):
                sections.append(f"{i}. {penalty['text']}")
                sections.append(f"   Fonte: {penalty['source']}")
                sections.append("")
        
        # Artigos importantes
        if analysis['key_articles']:
            sections.extend([
                "üìñ ARTIGOS IMPORTANTES:",
                ""
            ])
            for i, article in enumerate(analysis['key_articles'][:3], 1):
                sections.append(f"{i}. {article['text']}")
                sections.append(f"   Fonte: {article['source']}")
                sections.append("")
        
        # An√°lise focada
        if analysis['focus_analysis']:
            sections.extend([
                "üéØ AN√ÅLISE FOCADA:",
                ""
            ])
            for area, items in analysis['focus_analysis'].items():
                sections.append(f"‚ñ∫ {area.upper()}:")
                for item in items[:2]:
                    sections.append(f"  ‚Ä¢ {item['text']}")
                    sections.append(f"    Fonte: {item['source']}")
                sections.append("")
        
        sections.extend([
            "---",
            "NOTA: Esta an√°lise foi gerada automaticamente. Consulte sempre as fontes originais para decis√µes cr√≠ticas."
        ])
        
        return "\n".join(sections)